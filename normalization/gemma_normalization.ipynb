{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9667bed",
   "metadata": {},
   "source": [
    "# Gemma Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b706dd",
   "metadata": {},
   "source": [
    "Erstellen der Output-Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b30bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class NormalizationItem(BaseModel):\n",
    "    original: Optional[str] = None\n",
    "    Normalisiert: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38237434",
   "metadata": {},
   "source": [
    "`reisen02_filtered.json`, die zuvor in `corpus_creation.ipynb` erstellt wurde, wird als `input_json` definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3692ea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_json = \"reisen02_filtered.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cffc5",
   "metadata": {},
   "source": [
    "## Normalisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d368a4",
   "metadata": {},
   "source": [
    "Berechnungsdauer: 370 Minuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599230e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "# JSON-Datei laden\n",
    "with open(input_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "sentences = data[\"sentences\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "# durch die Sätze iterieren\n",
    "for sentence in sentences:\n",
    "    # orig_text wird am Ende des Prompts an das Modell übergeben.\n",
    "    orig_text = sentence[\"orig_sentence\"][\"text\"]\n",
    "    norm_text = sentence[\"norm_sentence\"][\"text\"]\n",
    "    sentence_id = sentence[\"sentence_id\"]\n",
    "\n",
    "    # Prompt für das Modell erstellen\n",
    "    prompt = f\"\"\"\n",
    "        Du bist ein KI-Assistent, der historische deutsche Texte normalisiert.\n",
    "        Deine Aufgabe ist es, die Othografie eines übergebenen Textes nach folgenden Regeln zu modernisieren:\n",
    "        - Ersetze veraltete Buchstaben und Zeichennutzung wie (ſ,uͤ,aͤ,oͤ,y,th), durch moderne Entsprechungen (s,ü,ä,ö,i,t).\n",
    "        Beispiel:[\n",
    "        \"Satz\": \"Zwey ſchoͤne Anhoͤhen ſahen wir im suͤdlichen Theil.\n",
    "        \"response\": \"Zwei schöne Anhöhen sahen wir im südlichen Teil.\"]\n",
    "        - Passe außschließlich die Orthografie an und ersetze keine Wörter.\n",
    "        Beispiel:[\n",
    "        \"Satz\": \"Einige Tage hernach ſa- hen wir Beſansſegel, auf dem Waſſer ſegeln.\"\n",
    "        \"response\": \"Einige Tage hernach sahen wir Besanssegel, auf dem Wasser segeln.\"]\n",
    "        - Verändere keine unbekannten Wörter, wenn die Orthografie an sich modern ist.\n",
    "        Beispiel:[\n",
    "        \"Satz\": \"Wir ſegelten ab, nachdem Capitain Morland auf dem Commandeurſchiffe Boven Kerkerpolder das Zeichen gegeben hatte.\"\n",
    "        \"response\": \"Wir segelten ab, nachdem Capitain Morland auf dem Commandeurschiffe Boven Kerkerpolder das Zeichen gegeben hatte.\"]\n",
    "        - Verändere keine Namen und Eigennamen.\n",
    "        Beispiel:[\n",
    "        \"Satz\": \"Unterwegs ſah ich die Capſche Miſtel (Viſcus capenſis), ein paraſitiſches Gewaͤchs.\"\n",
    "        \"response\": \"Unterwegs sah ich die Capsche Mistel (Viscus capensis), ein parasitisches Gewächs\"]\n",
    "\n",
    "    \"Satz\": {orig_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # Modell aufrufen\n",
    "    response = ollama.chat(\n",
    "    model='gemma3:12b',\n",
    "    messages=[\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": prompt,\n",
    "         \"temperature\": 0.2\n",
    "        }\n",
    "    ],\n",
    "    format=NormalizationItem.model_json_schema(),\n",
    "    )\n",
    "\n",
    "    result = NormalizationItem.model_validate_json(response.message.content)\n",
    "    print(response.message.content)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "    \"sentence_id\": sentence_id,\n",
    "    \"model_output\": result.Normalisiert,\n",
    "    \"norm_sentence\": norm_text\n",
    "    })\n",
    "\n",
    "output_file = \"normalization_results.json\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9720d987",
   "metadata": {},
   "source": [
    "In dem Normaliiserungsskript wurden die Originalsätze nicht zu der `.json`inzugefügt. Das wird hier nachgeholt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfcc637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisse aus results2.json laden\n",
    "results_file = \"results2.json\"\n",
    "with open(results_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Erweiterung der Ergebnisse um die originalen Sätze\n",
    "results_expanded = []\n",
    "\n",
    "for sentence, result in zip(sentences, results):\n",
    "    expanded_entry = {\n",
    "        \"sentence_id\": result[\"sentence_id\"],\n",
    "        \"orig_sentence\": sentence[\"orig_sentence\"][\"text\"],\n",
    "        \"model_output\": result[\"model_output\"],\n",
    "        \"norm_sentence\": result[\"norm_sentence\"]\n",
    "    }\n",
    "    results_expanded.append(expanded_entry)\n",
    "\n",
    "# Ergebnisse in einer neuen Datei speichern\n",
    "expanded_output_file = \"results_expanded.json\"\n",
    "with open(expanded_output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_expanded, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b5503",
   "metadata": {},
   "source": [
    "Um Ground Truth und die Normalisierung des Sprachmodells angemessen vergleichen zu können, werden nur die Sätze in eine jeweilige `.txt` übernommen, in denen auch Änderungen zwischen der Ground Truth und der Normaliiserung stattfinden. So wird vermieden, dass die Ergebnisse zu positiv ausfallen. Die bieden `.txt`s können anschließend dinglehopper für die Berechnung der `WER`s und `CER`s übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abce395a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der übertragenen Sätze: 5652\n",
      "Anzahl der ignorierten Sätze: 406\n"
     ]
    }
   ],
   "source": [
    "# Dateien für die Normalisierung erstellen\n",
    "gt_normalized_file = \"gt_normalized.txt\"\n",
    "llm_normalized_file = \"llm_normalized.txt\"\n",
    "\n",
    "transferred_count = 0\n",
    "ignored_count = 0\n",
    "\n",
    "with open(gt_normalized_file, \"w\", encoding=\"utf-8\") as gt_file, open(llm_normalized_file, \"w\", encoding=\"utf-8\") as llm_file:\n",
    "    for entry in results_expanded:\n",
    "        orig_sentence = entry[\"orig_sentence\"]\n",
    "        norm_sentence = entry[\"norm_sentence\"]\n",
    "        model_output = entry[\"model_output\"]\n",
    "\n",
    "        # Nur Sätze übertragen, bei denen sich etwas zwischen Original und Normalisierung ändert\n",
    "        if orig_sentence != norm_sentence:\n",
    "            gt_file.write(norm_sentence + \"\\n\")\n",
    "            llm_file.write(model_output + \"\\n\")\n",
    "            transferred_count += 1\n",
    "        else:\n",
    "            ignored_count += 1\n",
    "\n",
    "# Ausgabe der Anzahl der übertragenen und ignorierten Sätze\n",
    "print(f\"Anzahl der übertragenen Sätze: {transferred_count}\")\n",
    "print(f\"Anzahl der ignorierten Sätze: {ignored_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1d770a",
   "metadata": {},
   "source": [
    "Da sich aber auch in Sätzen, die keine Veränderungen erfahren sollen, Fehler befinden können, werden sie noch einmal überprüft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d636d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der Sätze, bei denen orig_sentence, norm_sentence und model_output identisch sind: 332\n"
     ]
    }
   ],
   "source": [
    "# Zählen der Sätze, bei denen alle drei Variablen identisch sind\n",
    "identical_count = 0\n",
    "\n",
    "for entry in results_expanded:\n",
    "    orig_sentence = entry[\"orig_sentence\"]\n",
    "    norm_sentence = entry[\"norm_sentence\"]\n",
    "    model_output = entry[\"model_output\"]\n",
    "\n",
    "    # Überprüfen, ob alle drei Variablen identisch sind\n",
    "    if orig_sentence == norm_sentence == model_output:\n",
    "        identical_count += 1\n",
    "\n",
    "# Ausgabe der Anzahl der identischen Sätze\n",
    "print(f\"Anzahl der Sätze, bei denen orig_sentence, norm_sentence und model_output identisch sind: {identical_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518cc93",
   "metadata": {},
   "source": [
    "Nachfolgend werden alle Sätze ausgegeben, bei denen Original und Normalisierung identisch sind, aber der Modelloutput etwas verändert hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61fef55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sätze, bei denen orig_sentence und norm_sentence identisch sind, aber model_output abweicht:\n",
      "orig_sentence: 14.\n",
      "norm_sentence: 14.\n",
      "model_output: vierzehn.\n",
      "\n",
      "orig_sentence: 32.\n",
      "norm_sentence: 32.\n",
      "model_output: Ich verstehe. Bitte geben Sie mir den zu normalisierenden Text.\n",
      "\n",
      "orig_sentence: 46.\n",
      "norm_sentence: 46.\n",
      "model_output: Die ſchon beſagte ſtarke Bewegung, welche wir von der See zuͤrük an das Ufer treibt, war nunmehr verſchwunden.\n",
      "\n",
      "orig_sentence: 4. Rothmannia, et nytt Örte-Genus.\n",
      "norm_sentence: 4. Rothmannia, et nytt Örte-Genus.\n",
      "model_output: 4. Rothmannia, et neue Örte-Genus.\n",
      "\n",
      "orig_sentence: 6. Anmärkningar vid Hydnora africana.\n",
      "norm_sentence: 6. Anmärkningar vid Hydnora africana.\n",
      "model_output: 6. Anmerkungen bei Hydnora africana.\n",
      "\n",
      "orig_sentence: 7.\n",
      "norm_sentence: 7.\n",
      "model_output: Sie wurden von dem Hofrath und dem Advocaten, welche in dem Theil des Hauses gewohneten, in freundlicher Weiſe aufgenommen.\n",
      "\n",
      "orig_sentence: 13. Noctua Serici, enny Silkes-malk.\n",
      "norm_sentence: 13. Noctua Serici, enny Silkes-malk.\n",
      "model_output: 13. Noctua Serici, ein Seidenmal.\n",
      "\n",
      "orig_sentence: ( Die Seideneule, Noctua Serici, ein neuer Seidenwurm ), 1781. 3 Qu. S. 240. 1 K. T\n",
      "norm_sentence: ( Die Seideneule, Noctua Serici, ein neuer Seidenwurm ), 1781. 3 Qu. S. 240. 1 K. T\n",
      "model_output: Die Seideneule, Noctua Serici, ein neuer Seidenwurm, 1781. 3 Qu. S. 240. 1 K. T\n",
      "\n",
      "orig_sentence: ( Weitere Bemerkungen, die Sternblume betreffend ), 1783. 3. Qu. S. 224.\n",
      "norm_sentence: ( Weitere Bemerkungen, die Sternblume betreffend ), 1783. 3. Qu. S. 224.\n",
      "model_output: (Weitere Bemerkungen, die Sternblume betreffend ), 1783. 3. Qu. S. 224.\n",
      "\n",
      "orig_sentence: 1783. Vol. IV.\n",
      "norm_sentence: 1783. Vol. IV.\n",
      "model_output: 1783. Bd. IV.\n",
      "\n",
      "orig_sentence: 1776. c. figg.\n",
      "norm_sentence: 1776. c. figg.\n",
      "model_output: 1776 c. figg.\n",
      "\n",
      "orig_sentence: 6. Syngnathi nova Species.\n",
      "norm_sentence: 6. Syngnathi nova Species.\n",
      "model_output: 6. Syngnathi neue Species.\n",
      "\n",
      "orig_sentence: 2. Cryptogamarnm fructificatio in Cycade et Zamia.\n",
      "norm_sentence: 2. Cryptogamarnm fructificatio in Cycade et Zamia.\n",
      "model_output: 2. Cryptogamarum fructificatio in Cycade et Zamia.\n",
      "\n",
      "orig_sentence: Inhalt.\n",
      "norm_sentence: Inhalt.\n",
      "model_output: Inhalt\n",
      "\n",
      "orig_sentence: Straet Banca.\n",
      "norm_sentence: Straet Banca.\n",
      "model_output: Straße Banca.\n",
      "\n",
      "orig_sentence: Fahrt bis zum Ankerplatze.\n",
      "norm_sentence: Fahrt bis zum Ankerplatze.\n",
      "model_output: Fahrt bis zum Ankerplatz.\n",
      "\n",
      "orig_sentence: Vortreffliches Procellain.\n",
      "norm_sentence: Vortreffliches Procellain.\n",
      "model_output: Vortreffliches Porzellan.\n",
      "\n",
      "orig_sentence: Aufenthalt zu Miako.\n",
      "norm_sentence: Aufenthalt zu Miako.\n",
      "model_output: Aufenthalt zu Mjako.\n",
      "\n",
      "orig_sentence: Angekommene Kranke.\n",
      "norm_sentence: Angekommene Kranke.\n",
      "model_output: Ankommene Kranke.\n",
      "\n",
      "orig_sentence: Bettelnonnen.\n",
      "norm_sentence: Bettelnonnen.\n",
      "model_output: Bettelnonnen\n",
      "\n",
      "orig_sentence: Provinz Owari.\n",
      "norm_sentence: Provinz Owari.\n",
      "model_output: Provinz Owari\n",
      "\n",
      "orig_sentence: Hafen.\n",
      "norm_sentence: Hafen.\n",
      "model_output: Hafen\n",
      "\n",
      "orig_sentence: Audienz-Zimmer.\n",
      "norm_sentence: Audienz-Zimmer.\n",
      "model_output: Audienz Zimmer.\n",
      "\n",
      "orig_sentence: Cerimonie der Audienz.\n",
      "norm_sentence: Cerimonie der Audienz.\n",
      "model_output: Zeremonie der Audienz.\n",
      "\n",
      "orig_sentence: Tempel zu Miako.\n",
      "norm_sentence: Tempel zu Miako.\n",
      "model_output: Tempel zu Mjako.\n",
      "\n",
      "orig_sentence: Neugier und Wißbegierde.\n",
      "norm_sentence: Neugier und Wißbegierde.\n",
      "model_output: Neugier und Wissbegierde.\n",
      "\n",
      "orig_sentence: Mangel an Meubeln in den Zimmern.\n",
      "norm_sentence: Mangel an Meubeln in den Zimmern.\n",
      "model_output: Mangel an Möbeln in den Zimmern.\n",
      "\n",
      "orig_sentence: Silberne.\n",
      "norm_sentence: Silberne.\n",
      "model_output: Silberne\n",
      "\n",
      "orig_sentence: Aere.\n",
      "norm_sentence: Aere.\n",
      "model_output: Äre.\n",
      "\n",
      "orig_sentence: Mondenjahr.\n",
      "norm_sentence: Mondenjahr.\n",
      "model_output: Mondejahr.\n",
      "\n",
      "orig_sentence: Luntenuhren.\n",
      "norm_sentence: Luntenuhren.\n",
      "model_output: Lutenuhren.\n",
      "\n",
      "orig_sentence: Zunder.\n",
      "norm_sentence: Zunder.\n",
      "model_output: Zunder\n",
      "\n",
      "orig_sentence: Denn alles, was wir zur Hand hatten, war naß, und mußte heraus gelegt, und getrocknet werden; manches war ganz verdorben.\n",
      "norm_sentence: Denn alles, was wir zur Hand hatten, war naß, und mußte heraus gelegt, und getrocknet werden; manches war ganz verdorben.\n",
      "model_output: Denn alles, was wir zur Hand hatten, war nass, und musste heraus gelegt, und getrocknet werden; manches war ganz verdorben.\n",
      "\n",
      "orig_sentence: Das Ganze war gegen den Regen mit einem Zelte von Segeltuch bedeckt.\n",
      "norm_sentence: Das Ganze war gegen den Regen mit einem Zelte von Segeltuch bedeckt.\n",
      "model_output: Das Ganze war gegen den Regen mit einem Zelt von Segeltuch bedeckt.\n",
      "\n",
      "orig_sentence: Vier Tage lang mußten wir hier verweilen.\n",
      "norm_sentence: Vier Tage lang mußten wir hier verweilen.\n",
      "model_output: Vier Tage lang mussten wir hier verweilen.\n",
      "\n",
      "orig_sentence: Diejenigen, welche wir hier davon aßen, waren vortrefflich.\n",
      "norm_sentence: Diejenigen, welche wir hier davon aßen, waren vortrefflich.\n",
      "model_output: Diejenigen, welche wir hier davon assen, waren vortrefflich.\n",
      "\n",
      "orig_sentence: Ich fand hier einen mir bisher ganz unbekannten Strauch, den ich Lindere ( Lindera ) nannte.\n",
      "norm_sentence: Ich fand hier einen mir bisher ganz unbekannten Strauch, den ich Lindere ( Lindera ) nannte.\n",
      "model_output: Ich fand hier einen mir bisher ganz unbekannten Strauch, den ich Lindera (Lindera) nannte.\n",
      "\n",
      "orig_sentence: Sei no Megin.\n",
      "norm_sentence: Sei no Megin.\n",
      "model_output: Sei nun Megin.\n",
      "\n",
      "orig_sentence: Kaij ba.\n",
      "norm_sentence: Kaij ba.\n",
      "model_output: Kai ba.\n",
      "\n",
      "orig_sentence: Die Winterhalbente ( Anas querquedula ):\n",
      "norm_sentence: Die Winterhalbente ( Anas querquedula ):\n",
      "model_output: Die Winterhalbente (Anas querquedula):\n",
      "\n",
      "orig_sentence: Man findet dergleichen daher auch im ganzen Lande nicht.\n",
      "norm_sentence: Man findet dergleichen daher auch im ganzen Lande nicht.\n",
      "model_output: Man findet dergleiche daher auch im ganzen Lande nicht.\n",
      "\n",
      "orig_sentence: Auch kann jeder das Seinige ohne langes Suchen kennen und finden.\n",
      "norm_sentence: Auch kann jeder das Seinige ohne langes Suchen kennen und finden.\n",
      "model_output: Auch kann jeder das Seine ohne langes Suchen kennen und finden.\n",
      "\n",
      "orig_sentence: Sie gilt 7 Mas, 5 Konderyn.\n",
      "norm_sentence: Sie gilt 7 Mas, 5 Konderyn.\n",
      "model_output: Sie gilt 7 Maß, 5 Konderyn.\n",
      "\n",
      "orig_sentence: 2. Us, Stier.\n",
      "norm_sentence: 2. Us, Stier.\n",
      "model_output: Us, Stier.\n",
      "\n",
      "orig_sentence: Porcellain.\n",
      "norm_sentence: Porcellain.\n",
      "model_output: Porzellan\n",
      "\n",
      "orig_sentence: Kompaß.\n",
      "norm_sentence: Kompaß.\n",
      "model_output: Kompaß\n",
      "\n",
      "orig_sentence: Endung der Perfecta und Participia.\n",
      "norm_sentence: Endung der Perfecta und Participia.\n",
      "model_output: Endung der Perfekta und Partizipien.\n",
      "\n",
      "orig_sentence: Partikeln.\n",
      "norm_sentence: Partikeln.\n",
      "model_output: Partikel\n",
      "\n",
      "orig_sentence: Japara.\n",
      "norm_sentence: Japara.\n",
      "model_output: Japara\n",
      "\n",
      "orig_sentence: Juana.\n",
      "norm_sentence: Juana.\n",
      "model_output: Juana\n",
      "\n",
      "orig_sentence: Ankunft zu Columbo.\n",
      "norm_sentence: Ankunft zu Columbo.\n",
      "model_output: Ankunft zu Colombo.\n",
      "\n",
      "orig_sentence: Gale.\n",
      "norm_sentence: Gale.\n",
      "model_output: Gale\n",
      "\n",
      "orig_sentence: Vom Kaneel.\n",
      "norm_sentence: Vom Kaneel.\n",
      "model_output: Vom Kanel.\n",
      "\n",
      "orig_sentence: Zimmetbaum.\n",
      "norm_sentence: Zimmetbaum.\n",
      "model_output: Zimmetbaum\n",
      "\n",
      "orig_sentence: Einpacken des Kaneels.\n",
      "norm_sentence: Einpacken des Kaneels.\n",
      "model_output: Einpacken des Kaneills.\n",
      "\n",
      "orig_sentence: Barringtonie.\n",
      "norm_sentence: Barringtonie.\n",
      "model_output: Barringtonie\n",
      "\n",
      "orig_sentence: Colombowurzel.\n",
      "norm_sentence: Colombowurzel.\n",
      "model_output: Colombowurzel\n",
      "\n",
      "orig_sentence: Boerhavie.\n",
      "norm_sentence: Boerhavie.\n",
      "model_output: Boerhaave.\n",
      "\n",
      "orig_sentence: Moringawurzel.\n",
      "norm_sentence: Moringawurzel.\n",
      "model_output: Moringawurzel\n",
      "\n",
      "orig_sentence: Stinkbaum.\n",
      "norm_sentence: Stinkbaum.\n",
      "model_output: Stinkbaum\n",
      "\n",
      "orig_sentence: Betelpfefferbaum.\n",
      "norm_sentence: Betelpfefferbaum.\n",
      "model_output: Betelpfefferbaum\n",
      "\n",
      "orig_sentence: Topas.\n",
      "norm_sentence: Topas.\n",
      "model_output: Topas\n",
      "\n",
      "orig_sentence: Robal.\n",
      "norm_sentence: Robal.\n",
      "model_output: Robal\n",
      "\n",
      "orig_sentence: Rubin.\n",
      "norm_sentence: Rubin.\n",
      "model_output: Rubin\n",
      "\n",
      "orig_sentence: Seite 233. bis 237.\n",
      "norm_sentence: Seite 233. bis 237.\n",
      "model_output: Seite 233 bis 237.\n",
      "\n",
      "orig_sentence: Texel.\n",
      "norm_sentence: Texel.\n",
      "model_output: Texel\n",
      "\n",
      "orig_sentence: Den Kompaß kennen und gebrauchen die Japaner.\n",
      "norm_sentence: Den Kompaß kennen und gebrauchen die Japaner.\n",
      "model_output: Den Kompass kennen und gebrauchen die Japaner.\n",
      "\n",
      "orig_sentence: Von Stunde an, wurde aber auch die Exportation des Silbers verboten.\n",
      "norm_sentence: Von Stunde an, wurde aber auch die Exportation des Silbers verboten.\n",
      "model_output: Von Stunde an wurde aber auch die Exportation des Silbers verboten.\n",
      "\n",
      "orig_sentence: Den 9ten April kam ich zu Samarang an.\n",
      "norm_sentence: Den 9ten April kam ich zu Samarang an.\n",
      "model_output: Den 9. April kam ich zu Samarang an.\n",
      "\n",
      "orig_sentence: Gegen Abend trafen wir zu Buytenzorg ein.\n",
      "norm_sentence: Gegen Abend trafen wir zu Buytenzorg ein.\n",
      "model_output: Gegen Abend trafen wir zu Butenzorg ein.\n",
      "\n",
      "orig_sentence: Vom Kaneel.\n",
      "norm_sentence: Vom Kaneel.\n",
      "model_output: Vom Kanel.\n",
      "\n",
      "orig_sentence: 3 ) Capuru Curundu, das heißt Kampferkaneel.\n",
      "norm_sentence: 3 ) Capuru Curundu, das heißt Kampferkaneel.\n",
      "model_output: Capuru Curundu, das heißt Kampferkaneel.\n",
      "\n",
      "orig_sentence: 6) Dawul Curundu, welches bedeutet platter oder Brettkaneel.\n",
      "norm_sentence: 6) Dawul Curundu, welches bedeutet platter oder Brettkaneel.\n",
      "model_output: Dawul Curundu, welches bedeutet platter oder Brettkanel.\n",
      "\n",
      "orig_sentence: Auch bekam ich hier Grammatica af.\n",
      "norm_sentence: Auch bekam ich hier Grammatica af.\n",
      "model_output: Auch bekam ich hier Grammatik ab.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sätze finden, bei denen orig_sentence und norm_sentence identisch sind, aber model_output abweicht\n",
    "differing_model_output = []\n",
    "\n",
    "for entry in results_expanded:\n",
    "    orig_sentence = entry[\"orig_sentence\"]\n",
    "    norm_sentence = entry[\"norm_sentence\"]\n",
    "    model_output = entry[\"model_output\"]\n",
    "\n",
    "    # Überprüfen, ob orig_sentence und norm_sentence identisch sind, aber model_output abweicht\n",
    "    if orig_sentence == norm_sentence and norm_sentence != model_output:\n",
    "        differing_model_output.append(entry)\n",
    "\n",
    "# Ausgabe der Sätze\n",
    "print(\"Sätze, bei denen orig_sentence und norm_sentence identisch sind, aber model_output abweicht:\")\n",
    "for entry in differing_model_output:\n",
    "    #print(f\"sentence_id: {entry['sentence_id']}\")\n",
    "    print(f\"orig_sentence: {entry['orig_sentence']}\")\n",
    "    print(f\"norm_sentence: {entry['norm_sentence']}\")\n",
    "    print(f\"model_output: {entry['model_output']}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
